{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "notebookId": "83d3d8a1-0069-4a10-a855-121ec7b89e45",
  "kernelspec": {
   "name": "python3",
   "display_name": "Yandex DataSphere Kernel",
   "language": "python"
  },
  "language_info": {
   "file_extension": ".py",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   },
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "cellId": "8calii1hw3vjs0v8lraom"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell for starting training\n",
    "# from start import init_train\n",
    "#\n",
    "# Trainer = init_train(\"configs/StyleGAN_256.json\", True)"
   ],
   "metadata": {
    "cellId": "zal4b1oam1rcuspg9rlgg",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from start import init_train\n",
    "from utils.images import SaveImages\n",
    "\n",
    "# Loading models and the latest weights without loading the dataset\n",
    "Trainer = init_train(\"configs/StyleGAN_256.json\", load_dataset=False)\n",
    "\n",
    "# Save 1000 randomly generated images to the img/256_2 folder\n",
    "SaveImages(Trainer, dir='img/256_2', cnt=1000)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "kltfhybix5gw7jd8ybpae",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# !tar -cvf img.tar img/256_2"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "0438yy6iedexsatxq0edlzm",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.images import TensorToImage\n",
    "\n",
    "plot_width, plot_height = 6, 20\n",
    "fig = plt.figure(figsize=(4 * plot_width, 4 * plot_height))\n",
    "\n",
    "z = torch.randn((plot_width * plot_height, 256), device=Trainer.device)\n",
    "for sample_n in range(1, plot_width * plot_height + 1):\n",
    "    ax = fig.add_subplot(plot_height, plot_width, sample_n)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.imshow(TensorToImage(Trainer.G(z[sample_n - 1])[0].detach().cpu(), 0.5, 0.4))\n",
    "    plt.title(sample_n - 1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "deo2d1btkdrwl6w5s73w",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from utils.video import GenerateVideo\n\ndef FromToVideo(z_1, z_2, frames=200):\n    samples = []\n    z_1 = z_1.to(Trainer.device)\n    z_2 = z_2.to(Trainer.device)\n    delta = ((z_2 - z_1)/(frames - 1)).to(Trainer.device)\n    for i in range(frames):\n        samples.append(Trainer.G(z_1 + i*delta).detach().cpu()[0])\n    return samples",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellId": "m4fgsk3333yqx3m5jpcfe",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "samples = []\nimages = [0, 44, 46, 115]\nfor to in tqdm(range(1, len(images))):\n    a = images[to - 1]\n    b = images[to]\n    samples_to = FromToVideo(z[a], z[b], 350)\n    samples = [*samples, *samples_to]\nsamples_to = FromToVideo(z[images[-1]], z[images[0]], 350)\nsamples = [*samples, *samples_to]\n\nGenerateVideo(samples, 1000/60, 0.5, 0.4)",
   "metadata": {
    "cellId": "r6pl9ye4y0phsp2z2x717d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "\n",
   "metadata": {
    "cellId": "ycq2l98fmupp17gjxd1nxn"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}